{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Make_Region_Maps.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAVbAafRwX3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "data_dir = '/content/drive/My Drive/Computer_Vision_final/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZaQ3F6_5QTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import dlib \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoOfnlvOY6lN",
        "colab_type": "text"
      },
      "source": [
        "Gather names of image files:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vrbQnJN4Jzm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Iterate through files in renaissance images folder and store names into array\n",
        "images = []\n",
        "local_download_path = data_dir + \"images/\"\n",
        "for filename in os.listdir(local_download_path):\n",
        "    tokens = filename.split(\".jpg\")\n",
        "    name = tokens[0]\n",
        "    images.append(str(name))\n",
        "print(images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfAEVT77i9em",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Iterate through files in male images folder and store names into array\n",
        "\n",
        "train_man_images = []\n",
        "local_path = data_dir + \"manwomandetection/dataset/train/man/\"\n",
        "for filename in os.listdir(local_path):\n",
        "    tokens = filename.split(\".jpg\")\n",
        "    name = tokens[0]\n",
        "    train_man_images.append(str(name))\n",
        "\n",
        "# Iterate through files in female images folder and store names into array\n",
        "train_woman_images = []\n",
        "local_path = data_dir + \"manwomandetection/dataset/train/woman/\"\n",
        "for filename in os.listdir(local_path):\n",
        "    tokens = filename.split(\".jpg\")\n",
        "    name = tokens[0]\n",
        "    train_woman_images.append(str(name))\n",
        "\n",
        "print(\"done\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUKbfzRzgZxN",
        "colab_type": "text"
      },
      "source": [
        "Function used to convert output of predictor (68 points) into list of coordinates: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GkgX53bLf21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shape_to_np(shape, dtype='int'):\n",
        "  # initialize the list of (x, y)-coordinates\n",
        "\tcoords = np.zeros((68, 2), dtype=dtype)\n",
        " \n",
        "\t# loop over the 68 facial landmarks and convert them\n",
        "\t# to a 2-tuple of (x, y)-coordinates\n",
        "\tfor i in range(0, 68):\n",
        "\t\tcoords[i] = (shape.part(i).x, shape.part(i).y)\n",
        " \n",
        "\t# return the list of (x, y)-coordinates\n",
        "\treturn coords\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMFyTg6TN24d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize facial detector and predictor for facial keypoints \n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor(data_dir + 'shape_predictor_68_face_landmarks.dat')\n",
        "\n",
        "def region_maps(srcdir, names, dstdir):\n",
        "  for name in names: \n",
        "      print(name)\n",
        "      im_path = data_dir + srcdir + str(name) + \".jpg\"\n",
        "      print(im_path)\n",
        "      im = cv2.imread(im_path, cv2.IMREAD_GRAYSCALE) #read image\n",
        "      h, w = im.shape\n",
        "\n",
        "      # cv2_imshow(im)\n",
        "\n",
        "      #run racial detector to get rectangular regions encompassing faces\n",
        "      rects = detector(im, 1) \n",
        "      face_objs = []\n",
        "      region_map = np.zeros((128, 128))\n",
        "\n",
        "      #iterate through detected faces, for our data, each image only has one face so only one region will be detected.\n",
        "      for (i, rect) in enumerate(rects): \n",
        "          shape = predictor(im, rect)\n",
        "          shape = shape_to_np(shape)\n",
        "\n",
        "\n",
        "          x = rect.left()\n",
        "          y = rect.top()\n",
        "          w = rect.right() - x\n",
        "          h = rect.bottom() - y\n",
        "\n",
        "          # print(\"size of face rectangles:\", h, w)\n",
        "\n",
        "          # region_map = np.zeros((h,w))\n",
        "          region_map = np.zeros((128, 128)) # initialize region map \n",
        "\n",
        "          \n",
        "          # To visualize where face was detected \n",
        "          cv2.rectangle(im, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "          cv2.putText(im, \"Face #{}\".format(i + 1), (x - 10, y - 10),\n",
        "            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "          \n",
        "          # for (x,y) in shape:\n",
        "          #     cv2.circle(im, (x,y), 1, (0, 0, 255), -1)\n",
        "              \n",
        "          # separate coordinates into different regions \n",
        "          jaw = shape[0:17]\n",
        "          nose = shape[27:35]\n",
        "          right_eye = shape[36:42]\n",
        "          right_brow = shape[17:22]\n",
        "          left_eye = shape[42:48]\n",
        "          left_brow = shape[22:27]\n",
        "          mouth = shape[48:68]\n",
        "\n",
        "          # f = face(jaw, nose, right_eye, right_brow, left_eye, left_brow, mouth)\n",
        "\n",
        "          # face_objs.append(f)\n",
        "\n",
        "          regions = [jaw, nose, right_eye, right_brow, left_eye, left_brow, mouth]  \n",
        "\n",
        "          # rgb = [, 25, 50]\n",
        "\n",
        "          # h, w = im.shape\n",
        "          \n",
        "          # iterate through regions and points in each region \n",
        "          for region in regions:\n",
        "            for (x,y) in region:\n",
        "              cv2.circle(im, (x,y), 3, 0, -1) # to visualize keypoints  \n",
        "              x2 = x - rect.left()\n",
        "              y2 = y - rect.top()\n",
        "              if x2 < w and y2 < h:\n",
        "                #shift keypoints to a 128x128 grid \n",
        "                x3 = int((x2 / w) * 128) \n",
        "                y3 = int((y2 / h) * 128)\n",
        "                region_map[y3,x3] = 1 # add point to regoin map\n",
        "      dstpath = data_dir + dstdir + str(name) + \".jpg\"\n",
        "      print(dstpath)\n",
        "      cv2.imwrite(dstpath, region_map) # save region map \n",
        "\n",
        "\n",
        "      # cv2_imshow(region_map)\n",
        "      cv2_imshow(im)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Px9ReQiHaghD",
        "colab_type": "text"
      },
      "source": [
        "Create region maps for renaissance images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33hVbgTolHJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "region_maps(\"images/\", images, \"region_maps/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSXPJq41aklQ",
        "colab_type": "text"
      },
      "source": [
        "Create region maps for BAM images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzT9QGZglVrV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "region_maps(\"manwomandetection/dataset/train/man/\", train_man_images, \"region_maps_train/\")\n",
        "region_maps(\"manwomandetection/dataset/train/woman/\", train_woman_images, \"region_maps_train/\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78lHfa-jB4sP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# path = data_dir + \"region_maps_train/\" + str(train_man_images[0]) + \".jpg\" #\"face_387w.jpg\"\n",
        "# print(path)\n",
        "# img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "# cv2_imshow(img)\n",
        "# img.shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}