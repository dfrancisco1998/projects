{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HBxwQ-1sOpB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "import argparse as ap"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-pDgJinu0ws",
        "colab_type": "code",
        "outputId": "7172512f-5f8f-42d1-a9a1-7d5d8d3132b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_dir = '/content/drive/My Drive/Computer_Vision_final/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKMt6_OUrV4f",
        "colab_type": "code",
        "outputId": "ba193d59-503a-4d4b-a3fb-fbc3f650457a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import os\n",
        "from tensorflow import keras\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKYS_1km2XnF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this is the stuff for testing \n",
        "csv_path = data_dir + \"face_labels.csv\"\n",
        "df = pd.read_csv(csv_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Garxkvc04Hs1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()\n",
        "col_file = list(df.file)\n",
        "col_file = col_file[:-2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAcBHc7SVOF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wI-cznjGr2rG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images = list()\n",
        "labels = list()\n",
        "#primary_path = data_dir + \"region_maps/\"\n",
        "#sub_dir_list = os.listdir(primary_path)\n",
        "for i in range(len(col_file)):\n",
        "  label = int(df['gender'][i])\n",
        "  holder = col_file[i].split(\".\")\n",
        "  name = holder[0] + \"_corners.jpg\"\n",
        "  path = data_dir + \"corners/\" + name\n",
        "  img = cv2.imread(path, cv2.IMREAD_GRAYSCALE) \n",
        "  image_data = np.array(img)\n",
        "  images.append(image_data)\n",
        "  labels.append(label)\n",
        "#x = np.array(images)\n",
        "test_features = np.array(images)\n",
        "labels = np.array(labels)\n",
        "#y = np.array(keras.utils.to_categorical(np.array(labels), num_classes=2))\n",
        "test_labels = np.array(keras.utils.to_categorical(np.array(labels), num_classes=2)) \n",
        "#train_features , test_features ,train_labels, test_labels = train_test_split( x , y , test_size=0.4 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiQSRTHmMQFG",
        "colab_type": "text"
      },
      "source": [
        "We have just loaded the contour maps in. Now what we want to do is to create a NN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL_u11HsRJKh",
        "colab_type": "text"
      },
      "source": [
        "FIRST WE WILL LOAD IN OUR TRAIN DATA>> SORRY IT IS BACKWARD!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iNCJLT9RIEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this is the stuff for testing \n",
        "csv_path_train = data_dir + \"face_train.csv\"\n",
        "df_train = pd.read_csv(csv_path_train)\n",
        "col_file_train = list(df_train.file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOENCKKOXYqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "col_file_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jh7ZzCpPz0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images_train = list()\n",
        "labels_train = list()\n",
        "primary_path = data_dir + \"corners/train/\"\n",
        "for i in range(len(col_file_train)):\n",
        "  label = int(df_train['gender'][i])\n",
        "  holder = col_file_train[i].split(\".\")\n",
        "  name = holder[0] + \"_corners.jpg\"\n",
        "  path = data_dir + \"corners/train/\" + name\n",
        "  img = cv2.imread(path, cv2.IMREAD_GRAYSCALE) \n",
        "  image_data = np.array(img)\n",
        "  \n",
        "  if image_data.shape == (0,0):\n",
        "    continue \n",
        "  \n",
        "  images_train.append(image_data)\n",
        "  labels_train.append(label)\n",
        "\n",
        "train_features = np.array(images_train)\n",
        "labels_train = np.array(labels_train)\n",
        "#y = np.array(keras.utils.to_categorical(np.array(labels_train), num_classes=2))\n",
        "train_labels = np.array(keras.utils.to_categorical(np.array(labels_train), num_classes=2))\n",
        "#train_features , test_features ,train_labels, test_labels = train_test_split( x_features , y , test_size=0.4 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csdyV4BTFyiB",
        "colab_type": "code",
        "outputId": "1d624da8-5912-432d-fbfa-c7d0d5b02c8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(train_features.shape)\n",
        "print(test_features.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1615, 128, 128)\n",
            "(169, 128, 128)\n",
            "(1615, 2)\n",
            "(169, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOdHNKosvFJW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtN3kOxxMZ4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras import models , optimizers , losses ,activations\n",
        "from tensorflow.python.keras.layers import *\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RA1cte0DMrFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classifier(object):\n",
        "    def __init__( self , number_of_classes, dimensions):\n",
        "        dropout_rate = 0.5\n",
        "        self.dimensions = dimensions\n",
        "        input_shape = ( dimensions**2 , )\n",
        "        convolution_shape = ( dimensions , dimensions , 1 )\n",
        "        kernel_size = (3 , 3)\n",
        "        pool_size = (2 , 2)\n",
        "        strides = 1\n",
        "        activation_func = activations.relu\n",
        "        self.layers = [\n",
        "            Reshape( input_shape=input_shape , target_shape=convolution_shape),\n",
        "            Conv2D( 32, kernel_size=( 4 , 4 ) , strides=strides , activation=activation_func),\n",
        "            MaxPooling2D(pool_size=pool_size, strides=strides ),\n",
        "            Conv2D( 64, kernel_size=( 3 , 3 ) , strides=strides , activation=activation_func),\n",
        "            MaxPooling2D(pool_size=pool_size , strides=strides),\n",
        "            Flatten(),\n",
        "            Dense( 100, activation=activation_func) ,\n",
        "            Dropout(dropout_rate),\n",
        "            Dense( number_of_classes, activation=tf.nn.softmax )\n",
        "        ]\n",
        "        self.model = tf.keras.Sequential(self.layers)\n",
        "        self.model.compile(\n",
        "            optimizer=optimizers.Adam(lr=.001),\n",
        "            loss=losses.categorical_crossentropy ,\n",
        "            metrics=['accuracy'] ,\n",
        "        )\n",
        "    def fit(self, X, Y, hyperparameters):\n",
        "        #if you want to not have that epoch printing you can just say verbose  = 0 in the .fit call \n",
        "        self.model.fit(X, Y, batch_size=hyperparameters['batch_size'], epochs=hyperparameters['epochs'], shuffle = True)  \n",
        "\n",
        "    def evaluate(self , test_X , test_Y) :\n",
        "        return self.model.evaluate(test_X, test_Y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = self.model.predict(X)\n",
        "        return predictions\n",
        "\n",
        "    def save_model(self , file_path ):\n",
        "        self.model.save(file_path )\n",
        "\n",
        "    def load_model(self , file_path ):\n",
        "        self.model = models.load_model(file_path)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJ6EW2nKPd8z",
        "colab_type": "text"
      },
      "source": [
        "Now to try and run "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcDFOc8kPdAK",
        "colab_type": "code",
        "outputId": "20a07817-62de-4e20-85e9-a6a0430ddcb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "data_dimension = 128\n",
        "train_features =  train_features.reshape( (  train_features.shape[0] , data_dimension**2  ) ).astype( np.float32 )\n",
        "test_features= test_features.reshape( ( test_features.shape[0] , data_dimension**2 ) ).astype( np.float32 )\n",
        "print(train_features.shape)\n",
        "print(test_features.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_labels.shape)\n",
        "\n",
        "classifier = Classifier( number_of_classes=2, dimensions = 128 )\n",
        "parameters = {\n",
        "    'batch_size' : 50 ,\n",
        "    'epochs' : 10,\n",
        "}\n",
        "classifier.fit(train_features , train_labels  , hyperparameters=parameters )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1615, 16384)\n",
            "(169, 16384)\n",
            "(1615, 2)\n",
            "(169, 2)\n",
            "Train on 1615 samples\n",
            "Epoch 1/10\n",
            "1615/1615 [==============================] - 3s 2ms/sample - loss: 120.4737 - acc: 0.6124\n",
            "Epoch 2/10\n",
            "1615/1615 [==============================] - 2s 1ms/sample - loss: 0.5167 - acc: 0.7659\n",
            "Epoch 3/10\n",
            "1615/1615 [==============================] - 2s 1ms/sample - loss: 0.3080 - acc: 0.8799\n",
            "Epoch 4/10\n",
            "1615/1615 [==============================] - 2s 1ms/sample - loss: 0.1578 - acc: 0.9362\n",
            "Epoch 5/10\n",
            "1615/1615 [==============================] - 2s 1ms/sample - loss: 0.0718 - acc: 0.9740\n",
            "Epoch 6/10\n",
            "1615/1615 [==============================] - 2s 1ms/sample - loss: 0.0435 - acc: 0.9851\n",
            "Epoch 7/10\n",
            "1615/1615 [==============================] - 2s 1ms/sample - loss: 0.0342 - acc: 0.9920\n",
            "Epoch 8/10\n",
            "1615/1615 [==============================] - 2s 1ms/sample - loss: 0.0338 - acc: 0.9901\n",
            "Epoch 9/10\n",
            "1615/1615 [==============================] - 2s 1ms/sample - loss: 0.0282 - acc: 0.9944\n",
            "Epoch 10/10\n",
            "1615/1615 [==============================] - 2s 1ms/sample - loss: 0.0235 - acc: 0.9907\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KJSIoPkWFfi",
        "colab_type": "code",
        "outputId": "b3bb0470-e39f-421d-a4b9-3e2182f2d61a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "#classifier.save_model( 'models/model.h5')\n",
        "preds = classifier.predict(test_features)\n",
        "loss , accuracy, FP, AUC, TP = classifier.evaluate( test_features , test_labels )\n",
        "print( \"Loss of {}\".format( loss ) , \"Accuracy of {} %\".format( accuracy * 100 ), \"False Positive {}\".format( FP ), \" TruePositive {}\".format( TP ), \"Area Under Curve{}\".format( AUC ) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "169/169 [==============================] - 0s 900us/sample - loss: 1.7010 - acc: 0.5740\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-3ef7079adec1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAUC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtest_features\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"Loss of {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m\"Accuracy of {} %\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"False Positive {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mFP\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" TruePositive {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mTP\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Area Under Curve{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mAUC\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 5, got 2)"
          ]
        }
      ]
    }
  ]
}